#!/usr/bin/env python

import signal
import threading
import logging

import sys

from myops2.lib import store
import rethinkdb as r
from rethinkdb.errors import RqlRuntimeError, RqlDriverError, RqlError, RqlTimeoutError

from myops2.settings import Config
from myops2.lib.queue import OrderedSetQueue
from myops2.monitor.workers.mooc import process_job
from myops2.monitor.workers.ripeJobAgent import ripe_process_job

logging.basicConfig(level=logging.ERROR,
                    format="%(asctime)s %(levelname)s [%(name)s] %(message)s",
                    datefmt="%Y-%m-%d %H:%M:%S",
                    filename="/var/log/myops2-mooc.log", filemode="a")

logger = logging.getLogger(__name__)

lock = threading.Lock()



def receive_signal(signum, stack):
    logger.info('Received signal %s', signum)

    #try :
    #    c = r.connect(host=Config.rethinkdb["host"], port=Config.rethinkdb["port"], db=Config.rethinkdb['db'])
    #except r.RqlDriverError :
    #    raise SystemExit("Can't connect to RethinkDB")

    #logger.info('Cleaning up (deleting all jobs)')
    #r.table("jobs").delete().run(c)

    raise SystemExit('Exiting')

def rethinkdb_connect():
    try:
        return r.connect(host=Config.rethinkdb["host"], port=Config.rethinkdb["port"], db=Config.rethinkdb['db'])
    except r.RqlDriverError:
        raise SystemExit("Can't connect to RethinkDB")

def rerun_jobs():
    pass

if __name__ == '__main__':

    signal.signal(signal.SIGINT, receive_signal)
    signal.signal(signal.SIGTERM, receive_signal)
    signal.signal(signal.SIGHUP, receive_signal)

    ''' input queue '''
    input = OrderedSetQueue()
    ripeInput = OrderedSetQueue()

    store.setup()

    # connection
    c = rethinkdb_connect()

    # setup
    try:
        r.db(Config.rethinkdb["db"]).table_create('jobs').run(c)
    except RqlRuntimeError:
        logger.info("table jobs already exists")

    # cleanup, put wait jobs int he queue
    table_jobs = r.table("jobs")
    waiting_jobs = table_jobs.filter({'jobstatus':'waiting'}).run(c)
    for job in waiting_jobs:
        logger.info("requeueing job {}".format(job['id']))
        try:
            if (job['type'] == "ripe"):
                ripeInput.put(job['id'])
            else:
                input.put(job['id'])
        except Exception as e:
            logger.error(e)

    # setup end
    #c.close(noreply_wait=False)

    semaphore_map = {}
    with open(sys.argv[1]) as node_list:
        for node in node_list:
            semaphore_map.update({node.strip(): threading.Semaphore(1)})

    # mooc threads
    threads = []
    for y in range(50):
        t = threading.Thread(target=process_job, args=(y, input, semaphore_map))
        t.daemon = True
        threads.append(t)
        t.start()
    
#    for y in range(4):
#        t = threading.Thread(target=ripe_process_job, args=(y, ripeInput))
#        t.daemon = True
#        threads.append(t)
#        t.start()


    # change feed
    feed = r.table('jobs').changes().run(c)

    for change in feed:
         job = change["new_val"]
         if (job['jobstatus'] == 'waiting'):
             if job["type"] == "ripe":
                 ripeInput.put(job['id'])
             else:
                 input.put(job['id'])
