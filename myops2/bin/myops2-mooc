#!/usr/bin/env python

import signal
import threading
import logging

import sys

from myops2.lib import store
import rethinkdb as r
from rethinkdb.errors import RqlRuntimeError, RqlDriverError, RqlError, RqlTimeoutError

from myops2.settings import Config
from myops2.lib.queue import OrderedSetQueue
from myops2.monitor.workers.mooc import process_job
from myops2.monitor.workers.ripeJobAgent import ripe_process_job

logging.basicConfig(level=logging.DEBUG,
                    format="%(asctime)s %(levelname)s [%(name)s] %(message)s",
                    datefmt="%Y-%m-%d %H:%M:%S")
#                    filename="/var/log/myops2-mooc.log", filemode="a")

logger = logging.getLogger(__name__)

lock = threading.Lock()



def receive_signal(signum, stack):
    logger.info('Received signal %s', signum)

    try :
        c = r.connect(host=Config.rethinkdb["host"], port=Config.rethinkdb["port"], db=Config.rethinkdb['db'])
    except r.RqlDriverError :
        raise SystemExit("Can't connect to RethinkDB")

    #logger.info('Cleaning up (deleting all jobs)')
    #r.table("jobs").delete().run(c)

    raise SystemExit('Exiting')

def rethinkdb_connect():
    try:
        return r.connect(host=Config.rethinkdb["host"], port=Config.rethinkdb["port"], db=Config.rethinkdb['db'])
    except r.RqlDriverError:
        raise SystemExit("Can't connect to RethinkDB")

def rerun_jobs():
    pass

if __name__ == '__main__':

    signal.signal(signal.SIGINT, receive_signal)
    signal.signal(signal.SIGTERM, receive_signal)
    signal.signal(signal.SIGHUP, receive_signal)

    ''' input queue '''
    input = OrderedSetQueue()
    ripeInput = OrderedSetQueue()

    store.setup()

    # connection
    c = rethinkdb_connect()

    # setup
    try:
        r.db(Config.rethinkdb["db"]).table_create('jobs').run(c)
    except RqlRuntimeError:
        logger.info("table jobs already exists")

    # cleanup, put wait jobs int he queue
    table_jobs = r.table("jobs")
    waiting_jobs = table_jobs.filter({'jobstatus':'waiting'}).run(c)
    for job in waiting_jobs:
        logger.info("requeueing job {}".format(job['id']))
        try:
            if (job['type'] == "ripe"):
                ripeInput.put(job['id'])
            else:
                input.put(job['id'])
        except Exception as e:
            logger.error(e)

    # setup end
    c.close(noreply_wait=False)

    semaphore_map = {}
    with open(sys.argv[1]) as node_list:
        for node in node_list:
            semaphore_map.update({node.strip(): threading.Semaphore(5)})

    # mooc threads
    threads = []
    for y in range(100):
        t = threading.Thread(target=process_job, args=(y, input, semaphore_map))
        t.daemon = True
        threads.append(t)
        t.start()

        t = threading.Thread(target=ripe_process_job, args=(y, ripeInput))
        t.daemon = True
        threads.append(t)
        t.start()

    while True:
        # connection
        c = rethinkdb_connect()

        # change feed
        feed = r.table('jobs').changes().run(c)

        while True:
            try:
                change = feed.next()
                job = change["new_val"]
                if (job['jobstatus'] == 'waiting'):
                    if job["type"] == "ripe":
                        ripeInput.put(job['id'])
                    else:
                        input.put(job['id'])

            except RqlTimeoutError:
                logger.warn("connection timeout, reconnecting...")

            except RqlDriverError:
                logger.warn("connection error, reconnecting...")
            finally:
                feed.close()
                c.close(noreply_wait=False)
                del c
                del feed
                break